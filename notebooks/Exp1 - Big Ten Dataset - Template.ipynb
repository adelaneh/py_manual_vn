{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Attribute) Value Normalization\n",
    "\n",
    "Attribute value normalization (value normalization for short) is one of the important steps in any data cleaning pipeline. Given a set of input values $V = \\{v_1, \\dots, v_m\\}$, we want to group them into subsets $\\{c_1, \\dots, c_n\\} = C$ such that for each $i \\neq j$, $c_i \\cap c_j = \\emptyset$ (i.e. $C$ is a partitioning of $V$), all the values in each $c_i$ refer to the same real-world entity and no two distinct groups $c_i$ and $c_j$ with $i\\neq j$ refer to the same entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Big Ten Dataset using Various Methods\n",
    "\n",
    "In the rest of this notebook, you try various methods to normalize different variations of the names of the Big Ten schools. First load the dataset by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import py_valuenormalization as vn\n",
    "vals = vn.read_from_file('../py_valuenormalization/data/big_ten.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``vals`` is a list of school name variations. Run the following commands to see a sample of these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "im = Image(filename='bigtensamplegoldenclusters.png')\n",
    "\n",
    "sample_vals = sorted(vals, key=lambda x: x.lower())[:20]\n",
    "sample_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "im": "<p><strong>NameError</strong>: name &#39;im&#39; is not defined</p>\n"
    }
   },
   "source": [
    "The correct clustering of these values looks like the following (run the following cell):\n",
    "{{im}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all the values in each group refer to the same school and no two distinct groups of values refer to the same school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Familiar with the Data and the Procedures\n",
    "\n",
    "Let's try normalizing this small sample using the following two value normalization approaches:\n",
    "\n",
    "   1. Manual\n",
    "   2. Clustering-based\n",
    "\n",
    "### Manual Value Normalization\n",
    "\n",
    "In manual value normalization, essentially you group together values which refer to the same school from scratch. Run the following command and follow the instructions to normalize the sample above manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(sample_man_clusts, time_to_finish) = vn.normalize_values(sample_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "time_to_finish": "<p><strong>NameError</strong>: name &#39;time_to_finish&#39; is not defined</p>\n"
    }
   },
   "source": [
    "It took you {{time_to_finish}} seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters you created are stored in the variable ``sample_man_clusts`` which is a dictionary where each key is the label of a cluster of ``sample_vals`` values, and the corresponding value is the list of data values in this cluster. We call such a dictionary a <i>cluster dictionary</i> from now on. Run the following command to see the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_man_clusts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering-based Value Normalization\n",
    "\n",
    "Manual value normalization could be cumbersome and very time-consuming, particularly when normalizing large datasets. To make the above process easier, we can use a clustering algorithm. At this step, we cluster the sample values using a standard clustering algorithm, i.e. hierarchical agglomerative clustering or HAC, by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hac = vn.HierarchicalClustering(sample_vals)\n",
    "\n",
    "sample_clusts = hac.cluster(\n",
    "    sim_measure = '3gram Jaccard', \n",
    "    linkage = 'single', \n",
    "    thr = 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatically formed clusters look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_clusts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the first cluster, that is ``'Buckeyes': ['Buckeyes', 'iowa hawkeyes']``: ``'Buckeyes'`` is the label of this cluster and the cluster contains the values ``'Buckeyes'`` and ``'iowa hawkeyes'``.\n",
    "\n",
    "As you can see, the HAC algorithm has clustered some of the values correctly. For example it has correctly grouped ``'Maryland'`` and ``'maryland'`` together.\n",
    "\n",
    "However some of the clusters are not correct. For example consider the first cluster again. ``'Buckeyes'`` and ``'iowa hawkeyes'`` do not refer to the same school. So we need to <i>split</i> this cluster into subclusters which contain values referring only to the same school. In this case, we split this cluster into two clusters each containing a single value.\n",
    "\n",
    "Then we need to <i>merge</i> the clusters ``'iowa hawkeyes': ['iowa hawkeyes']`` and ``'iowa': ['iowa']`` into a single cluster since they refer to the same school.\n",
    "\n",
    "To perform edits like above, run the following command and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(clean_sample_clusts, ttf) = vn.normalize_clusters(sample_clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting cluster dictionary ``clean_sample_clusts`` would look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_sample_clusts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Now that you have familiarized yourself with the basic concepts of and steps involved in value normalization, let's go through the actual experiments.\n",
    "\n",
    "To summarize, you are going to normalize the Big Ten dataset 7 times; thank you! For each experiment, we measure the time it would take you to normalize the values and compare them at the end. In order to remove the bias, we mask the actual method used for each experiment by naming methods 1 through 7. Just run the commands in the cell for each experiment and follow the instructions. Please pay as little attention to the cell contents as possible! ;) You'll see the final timing results after finishing all 7 experiments.\n",
    "\n",
    "**Important Note 1**: Please try to follow the instructions as closely as possible.\n",
    "\n",
    "**Important Note 2**: Please run all the cells to the end and save the notebook so we can access the experimental results later.\n",
    "\n",
    "**Important Note 3**: Please familiarize yourself with the data before starting the experiments below; i.e. look at all the values and make sure you know which school each value refers to. You will see a review screen immediately after you start the first method below. You can use that screen to learn all the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1\n",
    "\n",
    "Run the cell below and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "hac = vn.HierarchicalClustering(vals)\n",
    "van_8_clusts = hac.cluster(sim_measure = '3gram Jaccard', linkage = 'single', thr = 0.8)\n",
    "(van_8_clean_clusts, van_8_ttf) = vn.normalize_clusters(van_8_clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2\n",
    "\n",
    "Run the cell below and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "vn.HierarchicalClustering._default_thr = 0.3\n",
    "if 'training_pairs_3' not in locals() and 'training_pairs_3' not in globals():\n",
    "    (cm_3, training_pairs_3, calib_3_ttf) = vn.calibrate_normalization_cost_model(vals)\n",
    "smc = vn.SmartClustering(vals, training_pairs_3)\n",
    "(smt_3_clusts, best_setting_3) = smc.cluster()\n",
    "(agrscore_3, simk_3, lnk_3, thr_3) = best_setting_3\n",
    "(smt_3_clean_clusts, smt_3_ttf) = vn.normalize_clusters(smt_3_clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3\n",
    "\n",
    "Run the cell below and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "vn.HierarchicalClustering._default_thr = 0.8\n",
    "if 'cm_8' not in locals() and 'cm_8' not in globals():\n",
    "    (cm_8, training_pairs_8, calib_8_ttf) = vn.calibrate_normalization_cost_model(vals)\n",
    "hybhac = vn.HybridClustering(vals, cm_8)\n",
    "(hyb_8_clusts, hyb_8_mcl) = hybhac.cluster()\n",
    "(hyb_8_clean_clusts, hyb_8_ttf) = vn.normalize_clusters(hyb_8_clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4\n",
    "\n",
    "Run the cell below and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "(man_clean_clusts, man_ttf) = vn.normalize_values(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5\n",
    "\n",
    "Run the cell below and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "vn.HierarchicalClustering._default_thr = 0.3\n",
    "if 'cm_3' not in locals() and 'cm_3' not in globals():\n",
    "    (cm_3, training_pairs_3, calib_3_ttf) = vn.calibrate_normalization_cost_model(vals)\n",
    "hybhac = vn.HybridClustering(vals, cm_3)\n",
    "(hyb_3_clusts, hyb_3_mcl) = hybhac.cluster()\n",
    "(hyb_3_clean_clusts, hyb_3_ttf) = vn.normalize_clusters(hyb_3_clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6\n",
    "\n",
    "Run the cell below and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "hac = vn.HierarchicalClustering(vals)\n",
    "van_3_clusts = hac.cluster(sim_measure = '3gram Jaccard', linkage = 'single', thr = 0.3)\n",
    "(van_3_clean_clusts, van_3_ttf) = vn.normalize_clusters(van_3_clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7\n",
    "\n",
    "Run the cell below and follow the instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "vn.HierarchicalClustering._default_thr = 0.8\n",
    "if 'training_pairs_8' not in locals() and 'training_pairs_8' not in globals():\n",
    "    (cm_8, training_pairs_8, calib_8_ttf) = vn.calibrate_normalization_cost_model(vals)\n",
    "smc = vn.SmartClustering(vals, training_pairs_8)\n",
    "(smt_8_clusts, best_setting_8) = smc.cluster()\n",
    "(agrscore_8, simk_8, lnk_8, thr_8) = best_setting_8\n",
    "(smt_8_clean_clusts, smt_8_ttf) = vn.normalize_clusters(smt_8_clusts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Results\n",
    "\n",
    "Now let's compare the results for different methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "res_3 = {\n",
    "    'Manual': man_ttf,\n",
    "    'Vanilla with thr = 0.3': van_3_ttf,\n",
    "    'Smart with thr = 0.3': calib_3_ttf + smt_3_ttf,\n",
    "    'Hybrid with thr = 0.3': calib_3_ttf + hyb_3_ttf\n",
    "}\n",
    "\n",
    "rank_3 = sorted(res_3.keys(), key=lambda x: res_3[x])\n",
    "\n",
    "rank_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "res_8 = {\n",
    "    'Manual': man_ttf,\n",
    "    'Vanilla with thr = 0.8': van_8_ttf,\n",
    "    'Smart with thr = 0.8': calib_8_ttf + smt_8_ttf,\n",
    "    'Hybrid with thr = 0.8': calib_8_ttf + hyb_8_ttf\n",
    "}\n",
    "\n",
    "rank_8 = sorted(res_8.keys(), key=lambda x: res_8[x])\n",
    "\n",
    "rank_8"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
